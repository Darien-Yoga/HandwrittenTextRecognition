{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0cbf889e0a09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'function'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import editdistance\n",
    "from DataLoader import DataLoader, Batch\n",
    "from Model import Model, DecoderType\n",
    "from SamplePreprocessor import preprocess\n",
    "\n",
    "\n",
    "class FilePaths:\n",
    "\t\"filenames and paths to data\"\n",
    "\tfnCharList = '../model/charList.txt'\n",
    "\tfnAccuracy = '../model/accuracy.txt'\n",
    "\tfnTrain = '../data/'\n",
    "\tfnInfer = '../data/test.png'\n",
    "\tfnCorpus = '../data/corpus.txt'\n",
    "\n",
    "\n",
    "def train(model, loader):\n",
    "\t\"train NN\"\n",
    "\tepoch = 0 # number of training epochs since start\n",
    "\tbestCharErrorRate = float('inf') # best valdiation character error rate\n",
    "\tnoImprovementSince = 0 # number of epochs no improvement of character error rate occured\n",
    "\tearlyStopping = 5 # stop training after this number of epochs without improvement\n",
    "\twhile True:\n",
    "\t\tepoch += 1\n",
    "\t\tprint('Epoch:', epoch)\n",
    "\n",
    "\t\t# train\n",
    "\t\tprint('Train NN')\n",
    "\t\tloader.trainSet()\n",
    "\t\twhile loader.hasNext():\n",
    "\t\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\t\tbatch = loader.getNext()\n",
    "\t\t\tloss = model.trainBatch(batch)\n",
    "\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n",
    "\n",
    "\t\t# validate\n",
    "\t\tcharErrorRate = validate(model, loader)\n",
    "\t\t\n",
    "\t\t# if best validation accuracy so far, save model parameters\n",
    "\t\tif charErrorRate < bestCharErrorRate:\n",
    "\t\t\tprint('Character error rate improved, save model')\n",
    "\t\t\tbestCharErrorRate = charErrorRate\n",
    "\t\t\tnoImprovementSince = 0\n",
    "\t\t\tmodel.save()\n",
    "\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
    "\t\telse:\n",
    "\t\t\tprint('Character error rate not improved')\n",
    "\t\t\tnoImprovementSince += 1\n",
    "\n",
    "\t\t# stop training if no more improvement in the last x epochs\n",
    "\t\tif noImprovementSince >= earlyStopping:\n",
    "\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n",
    "\t\t\tbreak\n",
    "\n",
    "\n",
    "def validate(model, loader):\n",
    "\t\"validate NN\"\n",
    "\tprint('Validate NN')\n",
    "\tloader.validationSet()\n",
    "\tnumCharErr = 0\n",
    "\tnumCharTotal = 0\n",
    "\tnumWordOK = 0\n",
    "\tnumWordTotal = 0\n",
    "\twhile loader.hasNext():\n",
    "\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n",
    "\t\tbatch = loader.getNext()\n",
    "\t\t(recognized, _) = model.inferBatch(batch)\n",
    "\t\t\n",
    "\t\tprint('Ground truth -> Recognized')\t\n",
    "\t\tfor i in range(len(recognized)):\n",
    "\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
    "\t\t\tnumWordTotal += 1\n",
    "\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
    "\t\t\tnumCharErr += dist\n",
    "\t\t\tnumCharTotal += len(batch.gtTexts[i])\n",
    "\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
    "\t\n",
    "\t# print validation result\n",
    "\tcharErrorRate = numCharErr / numCharTotal\n",
    "\twordAccuracy = numWordOK / numWordTotal\n",
    "\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
    "\treturn charErrorRate\n",
    "\n",
    "\n",
    "def infer(model, fnImg):\n",
    "\t\"recognize text in image provided by file path\"\n",
    "\timg = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n",
    "\tbatch = Batch(None, [img])\n",
    "\t(recognized, probability) = model.inferBatch(batch, True)\n",
    "\tprint('Recognized:', '\"' + recognized[0] + '\"')\n",
    "\tprint('Probability:', probability[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "\t\"main function\"\n",
    "\t# optional command line args\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument('--train', help='train the NN', action='store_true')\n",
    "\tparser.add_argument('--validate', help='validate the NN', action='store_true')\n",
    "\tparser.add_argument('--beamsearch', help='use beam search instead of best path decoding', action='store_true')\n",
    "\tparser.add_argument('--wordbeamsearch', help='use word beam search instead of best path decoding', action='store_true')\n",
    "\tparser.add_argument('--dump', help='dump output of NN to CSV file(s)', action='store_true')\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\tdecoderType = DecoderType.BestPath\n",
    "\tif args.beamsearch:\n",
    "\t\tdecoderType = DecoderType.BeamSearch\n",
    "\telif args.wordbeamsearch:\n",
    "\t\tdecoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "\t# train or validate on IAM dataset\t\n",
    "\tif args.train or args.validate:\n",
    "\t\t# load training data, create TF model\n",
    "\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n",
    "\n",
    "\t\t# save characters of model for inference mode\n",
    "\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
    "\t\t\n",
    "\t\t# save words contained in dataset into file\n",
    "\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "\t\t# execute training or validation\n",
    "\t\tif args.train:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType)\n",
    "\t\t\ttrain(model, loader)\n",
    "\t\telif args.validate:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n",
    "\t\t\tvalidate(model, loader)\n",
    "\n",
    "\t# infer text on test image\n",
    "\telse:\n",
    "\t\tprint(open(FilePaths.fnAccuracy).read())\n",
    "\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True, dump=args.dump)\n",
    "\t\tinfer(model, FilePaths.fnInfer)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import collections\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.LSTM(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.LSTM(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x178d41d6b48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x00000178D41D6B48>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-72e1eabcb7ea>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-60-72e1eabcb7ea>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    A=[(num_units[n]=n) for n in num_units]\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "num_units = [256,256]\n",
    "i=3\n",
    "A=[(num_units[n]=n) for n in num_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'num_units' is an invalid keyword argument for print()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-f10d92e0620a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'num_units' is an invalid keyword argument for print()"
     ]
    }
   ],
   "source": [
    "for n in num_units:\n",
    "    print(num_units=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178DBA6C588>\n"
     ]
    }
   ],
   "source": [
    "y = tf.compat.v1.nn.rnn_cell.LSTMCell((n) for n in num_units)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178DBA4DF48>]\n"
     ]
    }
   ],
   "source": [
    "y = [tf.compat.v1.nn.rnn_cell.LSTMCell((num_units) for n in num_units)]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
